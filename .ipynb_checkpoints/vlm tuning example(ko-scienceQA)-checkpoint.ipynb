{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b89a1820-52b3-4f1b-8aa8-ac57b383d873",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install Pytorch & other libraries\n",
    "# %pip install \"torch==2.4.0\" \n",
    "%pip install -q tensorboard pillow wandb \n",
    " \n",
    "# Install Hugging Face libraries\n",
    "%pip install -q --upgrade \\\n",
    "  \"transformers==4.45.1\" \\\n",
    "  \"datasets==3.0.1\" \\\n",
    "  \"accelerate==0.34.2\" \\\n",
    "  \"evaluate==0.4.3\" \\\n",
    "  \"bitsandbytes==0.44.0\" \\\n",
    "  \"trl==0.11.1\" \\\n",
    "  \"peft==0.13.0\" \\\n",
    "  \"qwen-vl-utils\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e26e0361-81a8-44cf-9cf1-6cf9da30e064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q pillow -U"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00dee226-cb1e-4473-bc20-ebb5f6f38fcc",
   "metadata": {},
   "source": [
    "## 문제 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248ee39e-d9d6-44ee-b6a8-acf410fedd71",
   "metadata": {},
   "source": [
    "과제물 사진과 과제물 정보를 주고 실제 정답을 맞추는 모델을 개발합니다. \n",
    "\n",
    "이 모델은 선생님들이 학생들의 수행평가를 채점한다고 가정합니다. \n",
    "본 프로젝트는 실제 교육 현장의 데이터와 차이가 있을 수 있으나, 자동 채점 시스템의 기본 원리와 가능성을 탐구하는 데 중점을 둡니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289a4d54-537a-4dae-9386-2e66b8e8e67e",
   "metadata": {},
   "source": [
    "이번 예시에서는 Ko-SciecneQA 데이터셋을 사용할 건데요. 이 데이터셋은 12,726개의 아마존 제품의 제목, 이미지, 설명 및 메타데이터를 포함하고 있습니다.  \n",
    "이 중에서 이미지를 가지고 있는 6,218개의 데이터 중 시간 절약을 위해서 모두 사용하지는 않고 여기서 20%(1,243)만 사용하겠습니다.\n",
    "\n",
    "이미지, 문제, 힌트을 기반으로 정답을 생성하도록 모델을 파인튜닝하려 합니다.  \n",
    "따라서 이미지, 문제, 힌트를 포함한 입력을 만들고, 이를 이용하여 정답을 찾아보겠습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af977a22-1d6a-4977-a0f2-e2c5508695c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 참고: 이미지는 프롬프트에 직접 제공되지 않고 \"processor\"의 일부로 포함됨\n",
    "prompt= \"\"\"주어진 이미지와 ##ChOICES##, ##HINT##를 보고 정답을 맞추는 숙제 도우미입니다. 가장 적절한 정답을 맞추세요. \n",
    "\n",
    "##CHOICES##: {korean_choices}\n",
    "##HINT##: {korean_hint}\"\"\"\n",
    "\n",
    "system_message = \"당신은 이미지와 문제를 보고 문제를 맞추는 AI Assistant입니다.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f90aee6-602f-409e-a80f-3b06d855d202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "586dd8836410401fb80b4a2bf062568b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/881 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26bb60debb6d4ed6ac1ea34a59da3335",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/412M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dca8c5a0ec84bb09bca540c70712220",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/12726 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5df8662cc4d3452aa7b2980f4d967e73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/12726 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'system', 'content': [{'type': 'text', 'text': '당신은 이미지와 문제를 보고 문제를 맞추는 AI Assistant입니다.'}]}, {'role': 'user', 'content': [{'type': 'text', 'text': \"주어진 이미지와 ##ChOICES##, ##HINT##를 보고 정답을 맞추는 숙제 도우미입니다. 가장 적절한 정답을 맞추세요. \\n\\n##CHOICES##: ['신시내티', '링컨', '클리블랜드', '콜럼버스']\\n##HINT##: \"}, {'type': 'image', 'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=750x429 at 0x736F3828B690>}]}, {'role': 'assistant', 'content': [{'type': 'text', 'text': '콜럼버스'}]}]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# 데이터셋을 OpenAI 메시지 형식으로 변환하는 함수      \n",
    "def format_data(sample):\n",
    "   return {\"messages\": [\n",
    "               {\n",
    "                   \"role\": \"system\", # 시스템 역할\n",
    "                   \"content\": [{\"type\": \"text\", \"text\": system_message}], # 시스템 메시지\n",
    "               },\n",
    "               {\n",
    "                   \"role\": \"user\",  # 사용자 역할\n",
    "                   \"content\": [\n",
    "                       {\n",
    "                           \"type\": \"text\",\n",
    "                           # 제품명과 카테고리를 포함한 프롬프트 생성\n",
    "                           \"text\": prompt.format(korean_choices=sample[\"korean_choices\"], korean_hint=sample[\"korean_hint\"]),\n",
    "                       },{\n",
    "                           \"type\": \"image\", # 이미지 타입\n",
    "                           \"image\": sample[\"image\"] if sample[\"image\"] is not None else \"\", # 제품 이미지\n",
    "                       }\n",
    "                   ],\n",
    "               },\n",
    "               {\n",
    "                   \"role\": \"assistant\", # AI 어시스턴트 역할\n",
    "                   \"content\": [{\"type\": \"text\", \"text\": sample[\"answer_str\"]}], # 제품 설명\n",
    "               },\n",
    "           ],\n",
    "       }\n",
    "\n",
    "# 허브에서 데이터셋 로드\n",
    "dataset = load_dataset(\"daje/Ko-SciecneQA\", split=\"train\")\n",
    "dataset = dataset.filter(lambda example: example[\"image\"] is not None)\n",
    "# 데이터셋을 OpenAI 메시지 형식으로 변환\n",
    "# PIL.Image 타입을 유지하기 위해 리스트 컴프리헨션 사용 (.map()은 이미지를 바이트로 변환해버림)\n",
    "dataset = [format_data(sample) for sample in dataset]\n",
    "\n",
    "print(dataset[345][\"messages\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58727288-4b2d-4433-9251-4b0780b4853c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6218,\n",
       " {'messages': [{'role': 'system',\n",
       "    'content': [{'type': 'text',\n",
       "      'text': '당신은 이미지와 문제를 보고 문제를 맞추는 AI Assistant입니다.'}]},\n",
       "   {'role': 'user',\n",
       "    'content': [{'type': 'text',\n",
       "      'text': \"주어진 이미지와 ##ChOICES##, ##HINT##를 보고 정답을 맞추는 숙제 도우미입니다. 가장 적절한 정답을 맞추세요. \\n\\n##CHOICES##: ['신시내티', '링컨', '클리블랜드', '콜럼버스']\\n##HINT##: \"},\n",
       "     {'type': 'image',\n",
       "      'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=750x429>}]},\n",
       "   {'role': 'assistant', 'content': [{'type': 'text', 'text': '콜럼버스'}]}]})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset), dataset[345]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01b1d12d-ced0-433d-9be9-b9fe7d6d6c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 개수: 6218\n"
     ]
    }
   ],
   "source": [
    "# 위에 준 코드 실행 후\n",
    "train_dataset = dataset[:int(len(dataset) * 0.9)]\n",
    "test_dataset = dataset[int(len(dataset) * 0.9):]\n",
    "\n",
    "print(f\"데이터 개수: {len(dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac032fac-202c-4518-9e08-3625c06f1f6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5596, 622)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ed2dfd-268e-4d41-8873-2539df77131b",
   "metadata": {},
   "source": [
    "## trl의 SFTTrainer를 이용한 파인 튜닝"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111a92ab-c684-4885-a215-0be96ad28147",
   "metadata": {},
   "source": [
    "`trl`의 SFTTrainer를 사용해 모델을 파인튜닝할 건데요. SFTTrainer는 오픈소스 LLM과 VLM의 지도 파인튜닝을 매우 간단하게 만들어줍니다.  \n",
    "SFTTrainer는 `transformers` 라이브러리의 `Trainer`를 상속받아서 로깅, 평가, 체크포인트 등 모든 기능을 지원하면서도 추가적인 편의 기능을 제공합니다.\n",
    "\n",
    "이번 예시에서는 PEFT 기능을 사용할 예정입니다. PEFT 방법으로는 QLoRA를 사용할 건데, 이는 양자화와 LoRA 튜닝을 같이 사용하여 대규모 언어 모델의 메모리 사용량을 줄이는 기술입니다.\n",
    "\n",
    "* 참고: 멀티모달 입력에 패딩이 필요하기 때문에 Flash Attention은 사용할 수 없습니다.*\n",
    "\n",
    "Qwen 2 VL 7B 모델을 사용할 예정이지만, `model_id` 변수만 바꾸면 Meta AI의 Llama-3.2-11B-Vision, Mistral AI의 Pixtral-12B 등 다른 모델로도 쉽게 교체할 수 있습니다. bitsandbytes를 사용해 모델을 4비트로 양자화할 예정입니다.\n",
    "\n",
    "* 참고: 모델이 클수록 더 많은 메모리가 필요합니다. 이번 예시에서는 7B 모델을 사용할 예정입니다.*\n",
    "\n",
    "VLM 학습을 위해 LLM, 토크나이저, 프로세서를 올바르게 준비하는 것이 매우 중요합니다. 프로세서는 특수 토큰과 이미지를 입력에 포함시키는 역할을 담당하는 모듈입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fa661e-22e5-4843-87de-023ee47f71e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "849c84b2062b424a80ea62d9073eb0a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cdf33f769414bccb110309a2fb7f377",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unrecognized keys in `rope_scaling` for 'rope_type'='default': {'mrope_section'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ca48d733566488e88e1d4d720ba853e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/108k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96256d70d5644553ac246c3c9c4ea929",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "880b59be28664cccad96f3d0c0d32a5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00038.safetensors:   0%|          | 0.00/3.89G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52611ccad67440898ee072e7a62ce5e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00038.safetensors:   0%|          | 0.00/3.81G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e7afeaa036b421fb51534734826ad6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00038.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a35504d9d90243d1ba2515f12217e395",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00038.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec59e6f87f044ff9b0fb3365d06c75aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00005-of-00038.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40c37da7349046928d10d66f0b83dd97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00006-of-00038.safetensors:   0%|          | 0.00/3.81G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "773ee68cb3e14f0ca46aa54b08fa779d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00007-of-00038.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca8a07f2beed4acbbf53fe31b8761046",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00008-of-00038.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70e54781441145eeb258f69e501fb7c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00009-of-00038.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4b753a51e6546fbb821e70f346daf37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00010-of-00038.safetensors:   0%|          | 0.00/3.81G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1d87c13f16e401a95c0ddcaa47db7bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00011-of-00038.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ac9d3e0ffa343a3839e48e7b54c1578",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00012-of-00038.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc6fed0165bd4264aaf648cf3a1e384d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00013-of-00038.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce4ce22632114c93b16758bff7dc1ee2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00014-of-00038.safetensors:   0%|          | 0.00/3.81G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50215a8f2de24674815757ef61f1a6ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00015-of-00038.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66bce8b557a74937bbf7e7ac01ca3eb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00016-of-00038.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4e24df3dccc496d92546f2abd559e71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00017-of-00038.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "290972f508354b618214fb6d08a53e04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00018-of-00038.safetensors:   0%|          | 0.00/3.81G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6af98120c0b64987ac957905e64e2bf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00019-of-00038.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0802fc7e0f474ecb98ef5ccae686eaf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00020-of-00038.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c726ef694430481fa1fd9000d100b13f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00021-of-00038.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2f455a2b4f241ef9c579a257fec2bd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00022-of-00038.safetensors:   0%|          | 0.00/3.81G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7aaeb35dd6040f78968f8dac347d4c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00023-of-00038.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93908c69cf9a4be6824f2845f14c14b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00024-of-00038.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "505edf8cdbbf47d3a6025fea6b85b4cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00025-of-00038.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a45a44a36f04ca9bcba07187387fb8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00026-of-00038.safetensors:   0%|          | 0.00/3.81G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd41536d8ab64f48b7c92148a16ceb3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00027-of-00038.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d79518d7adb40e392c94e5d9d1964e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00028-of-00038.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "819c8a57cb27461fbd930eb775314119",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00029-of-00038.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f824df7509304d30b192cf42c67c17bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00030-of-00038.safetensors:   0%|          | 0.00/3.81G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb9ed84bb49343bfbc333a402e0ece9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00031-of-00038.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69a8cf4dff2647b48706ae11f94a95ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00032-of-00038.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02c263cad1b745d6aa7d743dbead11f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00033-of-00038.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForVision2Seq, AutoProcessor, BitsAndBytesConfig\n",
    "\n",
    "# 허깅페이스 모델 ID\n",
    "model_id = \"Qwen/Qwen2-VL-72B-Instruct\" \n",
    "\n",
    "# BitsAndBytes 4비트 양자화 설정\n",
    "# bnb_config = BitsAndBytesConfig(\n",
    "#    load_in_4bit=True,                             # 4비트 양자화 사용\n",
    "#    bnb_4bit_use_double_quant=True,               # 이중 양자화 사용으로 메모리 추가 절약\n",
    "#    bnb_4bit_quant_type=\"nf4\",                    # 4비트 양자화 타입 설정(normalized float 4)\n",
    "#    bnb_4bit_compute_dtype=torch.bfloat16         # 연산 시 bfloat16 타입 사용\n",
    "# )\n",
    "\n",
    "# 모델과 프로세서 로드\n",
    "model = AutoModelForVision2Seq.from_pretrained(\n",
    "   model_id,\n",
    "   device_map=\"auto\",                            # GPU 메모리에 자동 할당\n",
    "   # attn_implementation=\"flash_attention_2\",     # 학습시에는 flash attention 2 미지원\n",
    "   torch_dtype=torch.bfloat16,                   # bfloat16 정밀도 사용\n",
    "   # quantization_config=bnb_config                # 위에서 정의한 양자화 설정 적용\n",
    ")\n",
    "processor = AutoProcessor.from_pretrained(model_id)  # 텍스트/이미지 전처리기 로드"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf29d040-3ca9-4638-a8ae-f7d34bb461c6",
   "metadata": {},
   "source": [
    "다음은 QWEN의 템플릿 예시입니다.  \n",
    "\n",
    "```python\n",
    "<|im_start|>system\n",
    "시스템 프롬프트<|im_end|>\n",
    "<|im_start|>user\n",
    "사용자의 질문<|im_end|>\n",
    "<|im_start|>assistant\n",
    "거대 언어 모델의 답변<|im_end|>\n",
    "```\n",
    "\n",
    "멀티모달 QWEN은 이렇게 사용할 겁니다.\n",
    "\n",
    "```python\n",
    "<|im_start|>system\n",
    "시스템 프롬프트<|im_end|>\n",
    "<|im_start|>user\n",
    "사용자의 질문<|vision_start|>이미지<|vision_end|><|im_end|>\n",
    "<|im_start|>assistant\n",
    "거대 언어 모델의 답변<|im_end|>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e4a9eb-0886-41de-a168-6f045624825e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparation for inference\n",
    "text = processor.apply_chat_template(\n",
    "    dataset[2][\"messages\"], tokenize=False, add_generation_prompt=False\n",
    ")\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2acd65-fc31-4427-9d64-228efabdb5a4",
   "metadata": {},
   "source": [
    "SFTTrainer는 peft와 기본적으로 통합되어 있어 LoraConfig를 만들어서 트레이너에 제공하기만 하면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4890201-2cba-4de3-a5ed-bad569406b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig\n",
    "\n",
    "# LoRA config based on QLoRA paper & Sebastian Raschka experiment\n",
    "peft_config = LoraConfig(\n",
    "        lora_alpha=128,\n",
    "        lora_dropout=0.05,\n",
    "        r=256,\n",
    "        bias=\"none\",\n",
    "        target_modules=[\n",
    "            \"q_proj\",\n",
    "            \"up_proj\",\n",
    "            \"o_proj\",\n",
    "            \"k_proj\",\n",
    "            \"down_proj\",\n",
    "            \"gate_proj\",\n",
    "            \"v_proj\"],\n",
    "        task_type=\"CAUSAL_LM\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44497f73-c125-49d3-9530-9b5918ea75cb",
   "metadata": {},
   "source": [
    "학습을 시작하기 전에 사용할 하이퍼파라미터(SFTConfig)를 정의하고 입력이 모델에 올바르게 제공되는지 확인해야 합니다.  \n",
    "\n",
    "텍스트만 사용하는 지도 파인튜닝과 달리 모델에 이미지도 함께 제공해야 하는데요. 이를 위해 입력을 올바르게 포맷팅하고 이미지 특징을 포함하는 커스텀 DataCollator를 만들어야 합니다.  \n",
    "\n",
    "Qwen2 팀이 제공하는 유틸리티 패키지의 process_vision_info 메서드를 사용할 예정입니다. Llama 3.2 Vision 같은 다른 모델을 사용하는 경우라면, 동일한 방식으로 이미지 정보가 처리되는지 확인해봐야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6820033-24b8-4cf3-9514-2a7956fa26f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import SFTConfig\n",
    "from transformers import Qwen2VLProcessor\n",
    "from qwen_vl_utils import process_vision_info\n",
    "\n",
    "# SFTConfig를 통해 학습 설정을 정의\n",
    "args = SFTConfig(\n",
    "    output_dir=\"qwen2-72b-instruct-homeworks\",              # 학습된 모델과 체크포인트를 저장할 디렉터리 경로 및 리포지토리 ID\n",
    "    num_train_epochs=3,                                     # 전체 학습 에포크 수 (데이터셋을 몇 번 반복할지 설정)\n",
    "    per_device_train_batch_size=1,                          # 각 장비(GPU)당 사용될 배치 사이즈 (메모리와 연관됨)\n",
    "    gradient_accumulation_steps=8,                          # 경사 누적 스텝 수 (이 횟수만큼 기울기를 누적한 후 업데이트)\n",
    "    gradient_checkpointing=True,                            # 메모리 절약을 위한 gradient checkpointing 활성화 (메모리 최적화)\n",
    "    optim=\"adamw_torch_fused\",                              # AdamW 옵티마이저 (fused 버전 사용으로 학습 속도 향상)\n",
    "    logging_steps=5,                                        # 몇 스텝마다 로그를 출력할지 설정 (여기선 5 스텝마다 로그)\n",
    "    save_strategy=\"epoch\",                                  # 매 에포크마다 체크포인트 저장 설정\n",
    "    learning_rate=1e-5,                                     # 학습률 (QLoRA 논문에서 추천된 값 사용)\n",
    "    bf16=True,                                              # bfloat16 정밀도 사용 (메모리 절약 및 속도 향상)\n",
    "    tf32=True,                                              # tf32 정밀도 사용 (NVIDIA GPU에서 학습 속도 향상)\n",
    "    max_grad_norm=0.3,                                      # 기울기 클리핑을 위한 최대 기울기 값 (QLoRA 논문에서 추천된 값)\n",
    "    warmup_ratio=0.03,                                      # 학습 초기에 학습률을 점진적으로 올리는 warmup 비율 (QLoRA 논문에서 추천된 값)\n",
    "    lr_scheduler_type=\"constant\",                           # 일정한 학습률 스케줄러 사용 (학습률이 변하지 않음)\n",
    "    # push_to_hub=True,                                     # 학습된 모델을 Hugging Face Hub에 푸시할지 여부\n",
    "    report_to=\"tensorboard\",                                # TensorBoard를 통해 학습 상태를 모니터링\n",
    "    gradient_checkpointing_kwargs={\"use_reentrant\": False}, # reentrant gradient checkpointing 설정 (비재진입 방식 사용)\n",
    "    dataset_text_field=\"\",                                  # 데이터셋에서 텍스트 필드를 위한 더미 필드 (collator에서 필요)\n",
    "    dataset_kwargs={\"skip_prepare_dataset\": True}           # collator에서 데이터셋 전처리를 건너뛰기 위한 설정\n",
    ")\n",
    "\n",
    "# 불필요한 열 삭제하지 않도록 설정 (학습 중 사용되지 않는 열이라도 유지)\n",
    "args.remove_unused_columns = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8111c8-ac97-4cf0-94e6-340760b33792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트와 이미지 쌍을 인코딩하기 위한 데이터 collator 함수 정의\n",
    "def collate_fn(examples):\n",
    "    # 각 예제에서 텍스트와 이미지를 추출하고, 텍스트는 채팅 템플릿을 적용\n",
    "    texts = [processor.apply_chat_template(example[\"messages\"], tokenize=False) for example in examples]\n",
    "    image_inputs = [process_vision_info(example[\"messages\"])[0] for example in examples]\n",
    "\n",
    "    # 텍스트를 토크나이징하고 이미지를 처리하여 일괄 처리(batch) 형태로 변환\n",
    "    batch = processor(text=texts, images=image_inputs, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "    # labels로 사용할 input_ids 복사본 생성 후, 패딩 토큰을 -100으로 설정하여 손실 계산 시 무시하도록 함\n",
    "    labels = batch[\"input_ids\"].clone()\n",
    "    labels[labels == processor.tokenizer.pad_token_id] = -100  # 패딩 토큰 손실 계산 제외\n",
    "\n",
    "    # 특정 이미지 토큰 인덱스는 손실 계산에서 무시 (모델에 따라 다름)\n",
    "    if isinstance(processor, Qwen2VLProcessor):  \n",
    "        # Qwen2VL 모델의 이미지 토큰 인덱스\n",
    "        image_tokens = [151652, 151653, 151655]\n",
    "    else:\n",
    "        # 다른 모델에서 이미지 토큰 ID를 얻어 손실 계산에서 제외\n",
    "        image_tokens = [processor.tokenizer.convert_tokens_to_ids(processor.image_token)]\n",
    "    \n",
    "    # 손실 계산 시 이미지 토큰 인덱스를 무시하도록 설정\n",
    "    for image_token_id in image_tokens:\n",
    "        labels[labels == image_token_id] = -100\n",
    "    \n",
    "    # 배치에 labels 추가 (손실 계산 시 사용)\n",
    "    batch[\"labels\"] = labels\n",
    "\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a349f087-67c9-4d56-bf56-acbc4768e750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단일 예시 확인\n",
    "example = dataset[0]  # 데이터셋의 첫 번째 아이템\n",
    "print(\"단일 예시 데이터:\")\n",
    "print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb461049-7b7d-40a4-967e-76d57e95e68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collate_fn 테스트 (배치 크기 1로)\n",
    "batch = collate_fn([example])\n",
    "print(\"\\n처리된 배치 데이터:\")\n",
    "print(\"입력 ID 형태:\", batch[\"input_ids\"].shape)\n",
    "print(\"어텐션 마스크 형태:\", batch[\"attention_mask\"].shape)\n",
    "print(\"이미지 픽셀 형태:\", batch[\"pixel_values\"].shape)\n",
    "print(\"레이블 형태:\", batch[\"labels\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c15c695-c95e-4345-a898-25248bf37eb8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('입력에 대한 정수 인코딩 결과:')\n",
    "print(batch[\"input_ids\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e79ead1-5782-41c9-a818-2b86a68b0eed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('레이블에 대한 정수 인코딩 결과:')\n",
    "print(batch[\"labels\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f93c39-a403-4ad5-808c-5d2d9382ee76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 토큰 디코딩 예시 (입력 텍스트가 어떻게 변환되었는지 확인)\n",
    "decoded_text = processor.tokenizer.decode(batch[\"input_ids\"][0])\n",
    "print(\"\\n디코딩된 텍스트:\")\n",
    "print(decoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4567378a-89d7-44d4-ad0c-e093427a3cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import SFTTrainer\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    "    data_collator=collate_fn,\n",
    "    dataset_text_field=\"\",\n",
    "    peft_config=peft_config,\n",
    "    tokenizer=processor.tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d22539-530b-4474-9d78-883107717dec",
   "metadata": {},
   "source": [
    "Trainer 인스턴스의 train() 메서드를 호출하여 모델 학습을 시작합니다.  \n",
    "이렇게 하면 학습 루프가 시작되고 3 에폭 동안 모델이 학습됩니다. PEFT 방법을 사용하고 있기 때문에 전체 모델이 아닌 조정된 모델 가중치만 저장할 예정입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f037e1-c34c-402c-8d94-d49269c50292",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 학습 시작, 모델은 자동으로 허브와 출력 디렉토리에 저장됨\n",
    "trainer.train()\n",
    "\n",
    "# 모델 저장\n",
    "trainer.save_model(args.output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be8fdf9-41fc-4485-ac5d-5bee583714bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!huggingface-cli login --token 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\n",
    "\n",
    "hub_model_id = \"daje/Qwen2-VL-72B-instruct-ScienceQA-LoRA\"\n",
    "# 허깅페이스 업로드 \n",
    "model.push_to_hub(hub_model_id)\n",
    "processor.push_to_hub(hub_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7db6ce71-f50c-4595-b534-baf14aa9021a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 메모리 비우기\n",
    "del model\n",
    "del processor\n",
    "del trainer\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f493b6f7-8711-498e-b9b4-c5c54d290241",
   "metadata": {},
   "source": [
    "## 인퍼런스"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e955e49d-3dfc-41f0-9646-71f1eb1bb632",
   "metadata": {},
   "source": [
    "학습이 완료된 후에는 모델을 평가하고 테스트해볼 예정입니다.  \n",
    "\n",
    "먼저 기본 모델을 불러와서 임의의 아마존 제품에 대한 설명을 생성해보고, 그 다음 Q-LoRA로 조정된 모델을 불러와 같은 제품에 대한 설명을 생성해볼 것입니다.  \n",
    "마지막으로 더 효율적인 추론을 위해 어댑터를 기본 모델과 병합한 뒤, 동일한 제품에 대해 다시 한 번 추론을 실행해볼 예정입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff2460c2-f0fe-45b5-a706-c36f6d181dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"Qwen/Qwen2-VL-72B-Instruct\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2788d0eb-7739-44ea-89a8-0ca97728fe1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unrecognized keys in `rope_scaling` for 'rope_type'='default': {'mrope_section'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce009479ed2c4462bacedce03fc6896b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/108k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e50537486ab34907a04be206c29192db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a0ff6087c3c4061bc982cb2ab632eec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00038.safetensors:   0%|          | 0.00/3.89G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5aadd32c451479d85c05b0e925527a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00038.safetensors:   0%|          | 0.00/3.81G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e07a93b331884660afff367645a4415c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00038.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53eb632892ff43c5848a5af9621ec3ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00038.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4c467e044324bf8a96358e5293d9963",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00005-of-00038.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31c11e07986b4dd88f46c4664298265b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00006-of-00038.safetensors:   0%|          | 0.00/3.81G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e284ec37385149eb8f83405de09a1a36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00007-of-00038.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a449b5ce49c5440c98662a36a8684f35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00008-of-00038.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ad1c031929e4076bb72d88d02d4d1a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00009-of-00038.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b166f02783d48bebe9e58029964f702",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00010-of-00038.safetensors:   0%|          | 0.00/3.81G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fb5787c8a434dcd8d86f09879902f7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00011-of-00038.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e24dbeb3472a415180e2fda11d6c1a70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00012-of-00038.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77939a9a4831427089bf6703620c18b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00013-of-00038.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19b5fefa0b9f435ab32a72dbed1abe1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00014-of-00038.safetensors:   0%|          | 0.00/3.81G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9993e75417b340788f740540d9b28466",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00015-of-00038.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04a590318ed745bf8039e1fbaf03d646",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00016-of-00038.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e558a114f0364f1e8feb613ad767b8ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00017-of-00038.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fad1cc9c9e9474bbcaaa5de79ed81d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00018-of-00038.safetensors:   0%|          | 0.00/3.81G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a93dd4d9379430c81c4ee7c6212bfd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00019-of-00038.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7260771075d43f8b8e7a69bad8673cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00020-of-00038.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ac5ce7e418f45dbbdf677ede7131752",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00021-of-00038.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5c166efcbeb49bfb4aa10d95c87226a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00022-of-00038.safetensors:   0%|          | 0.00/3.81G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70359eea01ba485c81e055bffa7b57c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00023-of-00038.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b9fa9455c504f118555dbace7563a96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00024-of-00038.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a43f1dc746e40f1afb309ca842fd803",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00025-of-00038.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f58b4c7e99c471997545e408750e1ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00026-of-00038.safetensors:   0%|          | 0.00/3.81G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c284f3ec0a8f4a1d9b2871bccab7965f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00027-of-00038.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc6e17e2b82d4de9b43bbf1abcf724e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00028-of-00038.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b2490a98775464e9b44672f558e7b42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00029-of-00038.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa85a39c76f34a32b85a414c3e352796",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00030-of-00038.safetensors:   0%|          | 0.00/3.81G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e6450defebd455a85a9db4863cb14b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00031-of-00038.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa0d7afe5e074af08750ca74528a355a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00032-of-00038.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebc6beefadb24c80a2afbe83153b1835",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00033-of-00038.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "987e6c7664524cba965830fcb9559f2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00034-of-00038.safetensors:   0%|          | 0.00/3.81G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "041f2b49c0344ce4b0643823df664574",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00035-of-00038.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4f9f845ec9c48a1a8b7ce649d932904",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00036-of-00038.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86399ea53fe3413dbcfd88cadcb1dfb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00037-of-00038.safetensors:   0%|          | 0.00/2.24G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b78aff7838f84da68f39a5331dca2763",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00038-of-00038.safetensors:   0%|          | 0.00/2.49G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Qwen2VLRotaryEmbedding` can now be fully parameterized by passing the model config through the `config` argument. All other arguments will be removed in v4.46\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6627376ddeb2479c8302edef89476180",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad973bf757674e0f8171408de53c7094",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chat_template.json:   0%|          | 0.00/1.05k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoProcessor, AutoModelForVision2Seq\n",
    " \n",
    "# 기본 모델 호출\n",
    "model = AutoModelForVision2Seq.from_pretrained(\n",
    "  model_id,\n",
    "  device_map=\"auto\",\n",
    "  torch_dtype=torch.float16\n",
    ")\n",
    "processor = AutoProcessor.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee8d5bc4-1f96-495f-8dba-6e1a5dc3147c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 답변을 생성하는 함수\n",
    "def generate_description(messages, model, processor):\n",
    "   # 추론을 위한 준비\n",
    "   text = processor.apply_chat_template(\n",
    "       messages, tokenize=False, add_generation_prompt=True\n",
    "   )\n",
    "   image_inputs, video_inputs = process_vision_info(messages)\n",
    "   inputs = processor(\n",
    "       text=[text],\n",
    "       images=image_inputs,\n",
    "       videos=video_inputs,\n",
    "       padding=True,\n",
    "       return_tensors=\"pt\",\n",
    "   )\n",
    "   inputs = inputs.to(model.device)\n",
    "   # 추론: 출력 생성\n",
    "   generated_ids = model.generate(**inputs, max_new_tokens=128, top_p=1.0, do_sample=True, temperature=0.1)\n",
    "   generated_ids_trimmed = [out_ids[len(in_ids) :] for in_ids, out_ids in zip(inputs.input_ids, generated_ids)]\n",
    "   output_text = processor.batch_decode(\n",
    "       generated_ids_trimmed, skip_special_tokens=True, clean_up_tokenization_spaces=False\n",
    "   )\n",
    "   return output_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "af2c867f-da30-41aa-b1b9-b9da5f7130d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "소금물에서 더 잘 뜨나요.\n"
     ]
    }
   ],
   "source": [
    "# 정답 예측해보기\n",
    "messages =  test_dataset[0][\"messages\"]\n",
    "base_description = generate_description(messages, model, processor)\n",
    "print(base_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ef1eb96-3072-49c7-aac8-44dd12c27f64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82575aeb16df407ba16e20c3d8ed4b3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/622 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 정답 여러개 예측하기 \n",
    "no_train_result = [] \n",
    "\n",
    "for idx in tqdm(range(len(test_dataset))):\n",
    "    messages =  test_dataset[idx][\"messages\"]\n",
    "    base_description = generate_description(messages, model, processor)\n",
    "    no_train_result.append(base_description)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d2faefc7-68c9-4f1a-9682-8c55f6274d83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['계란이 민물에서 더 잘 뜨나요, 아니면 소금물에서 더 잘 뜨나요?', '두 쌍의 자기력 크기는 같습니다.']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \n",
    "answers = [data[\"messages\"][2][\"content\"][0][\"text\"] for data in test_dataset]\n",
    "answers[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee72ee6d-ab87-4e81-8a6d-f2873f45ccf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "226"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습하지 않은 모델로 정답과 비교하기 \n",
    "score = 0 \n",
    "for inference, answer in zip(no_train_result, answers):\n",
    "    if inference == answer : \n",
    "        score += 1\n",
    "score "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8c2f9a-cfef-4e1c-ba23-492e892f422c",
   "metadata": {},
   "source": [
    "학습을 하지 않은 상태에서 예측을 하면 622개 중 226개를 맞추는 것을 확인할 수 있습니다.   \n",
    "이번에는 학습한 로라 어댑터를 불어와서 예측해보겠습니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "94ced566-c1b3-438b-8b73-ffad356a5d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로라 어댑터가 있는 경로\n",
    "adapter_path = \"./qwen2-72b-instruct-homeworks\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6eb17220-fd25-4ae6-bf99-37d13ba25add",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로라 모델을 불러오기 \n",
    "model.load_adapter(adapter_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a85779d1-ad4f-4ab0-a27a-959113b6f53e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "소금물에서 더 잘 뜨나요?\n"
     ]
    }
   ],
   "source": [
    "# 1개 예측해보기 \n",
    "ft_description = generate_description(messages, model, processor)\n",
    "print(ft_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bb02fee1-4ea9-4085-94ab-3b08981c1fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoRA 학습 전 모델: 소금물에서 더 잘 뜨나요.\n",
      "---\n",
      "LoRA 학습 후 모델: 소금물에서 더 잘 뜨나요?\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습 전후 결과 비교 \n",
    "print('LoRA 학습 전 모델:', base_description)\n",
    "print('---')\n",
    "print('LoRA 학습 후 모델:', ft_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "771b5498-4d72-4309-8f48-d4d52cd94f1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "331fc9c148ae482893dd80cb34bd2768",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/622 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 학습한 모델로 예측하기 \n",
    "results = [] \n",
    "for idx in tqdm(range(len(test_dataset))):\n",
    "    messages =  test_dataset[idx][\"messages\"]\n",
    "    ft_description = generate_description(messages, model, processor)\n",
    "    results.append(ft_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "43c7b25a-21f9-442d-806c-fd9eaa654067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['소금물에서 더 잘 뜨나요?',\n",
       " '두 쌍의 자기력 크기는 같습니다.',\n",
       " '매사추세츠',\n",
       " '피닉스',\n",
       " '용액 B',\n",
       " '델라웨어',\n",
       " '샘플 B',\n",
       " '메릴랜드',\n",
       " '호주',\n",
       " '끌어당기다']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예측한 결과 10개 살펴보기 \n",
    "results[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3618c6df-4c2f-41f0-823e-b3688650e713",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "484"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = 0 \n",
    "for result, answer in zip(results, answers):\n",
    "    if result == answer : \n",
    "        score += 1\n",
    "score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b5466291-b7f6-47dc-a2b0-1bd31cf89610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 전 정답률 : 34.14%\n",
      "학습 후 정답률 : 73.11%\n"
     ]
    }
   ],
   "source": [
    "print(f\"학습 전 정답률 : {226/662*100:.2f}%\")\n",
    "print(f\"학습 후 정답률 : {484/662*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f61ce42-4217-49a0-b309-7107c7de31ab",
   "metadata": {},
   "source": [
    "## 로라 병합 후 저장하는 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c403983e-ef72-48ea-9376-0bfaa529c5c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unrecognized keys in `rope_scaling` for 'rope_type'='default': {'mrope_section'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54870841f8f441e5943a46774015c534",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from peft import PeftModel\n",
    "from transformers import AutoProcessor, AutoModelForVision2Seq\n",
    "\n",
    "adapter_path = \"./qwen2-7b-instruct-homeworks\"  # 학습된 어댑터 경로\n",
    "base_model_id = \"Qwen/Qwen2-VL-72B-Instruct\"  # 기본 모델 ID\n",
    "merged_path = \"merged\"  # 병합된 모델을 저장할 경로\n",
    "\n",
    "# 기본 모델 로드\n",
    "model = AutoModelForVision2Seq.from_pretrained(model_id, low_cpu_mem_usage=True)\n",
    "\n",
    "# 병합된 모델 저장 경로\n",
    "# LoRA와 기본 모델을 병합하고 저장\n",
    "peft_model = PeftModel.from_pretrained(model, adapter_path)  # PEFT 모델 로드\n",
    "merged_model = peft_model.merge_and_unload()  # 모델 병합\n",
    "merged_model.save_pretrained(merged_path,safe_serialization=True, max_shard_size=\"2GB\")  # 병합된 모델 저장\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(base_model_id)  # 프로세서 로드\n",
    "processor.save_pretrained(merged_path)  # 프로세서 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bf832bf-a68d-4677-b50f-53e45497f60b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95f77836272640dcb43c25581264eea1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unrecognized keys in `rope_scaling` for 'rope_type'='default': {'mrope_section'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "238a5bef9cec4460b8fa1e4acb6db40d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/108k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ae40c4b3a2b4fcbab30d38b6f8ec2f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fdb281f77e54ecd9dda678fa555e5d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00038.safetensors:   0%|          | 0.00/3.89G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00a92060f2844cc1909e8eedd84b1499",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00038.safetensors:   0%|          | 0.00/3.81G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "947cc31e6cd24989a209f5ae419639d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00038.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33bfd1269ef44f74a1ab16b8e15dd3d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00038.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a15885cddb64113b1af8eff5b8581b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00005-of-00038.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8861ef391cd741609b96912b96428084",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00006-of-00038.safetensors:   0%|          | 0.00/3.81G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a33b9a255cb34ebca46f77886b784f23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00007-of-00038.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "667bc5367e354204a76ae0a6509616dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00008-of-00038.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1f99c3b76684b728207df718dd42ab8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00009-of-00038.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e2538b4c64949d59d1788fe74478b10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00010-of-00038.safetensors:   0%|          | 0.00/3.81G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2761e8e3ad704808970a1f8ce5c870c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00011-of-00038.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b950d343f0ae43ed813d8284a8320a23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00012-of-00038.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4662c0e0d054471daa702a7250821d0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00013-of-00038.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c961c4e4caf14a42b0dee6a70db49b1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00014-of-00038.safetensors:   0%|          | 0.00/3.81G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3e64913bc174be9a92e375bab1404fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00015-of-00038.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58ad80a21e6c4a38b04ebc452326b585",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00016-of-00038.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13eeed82a08047a8a03be32f917fb9ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00017-of-00038.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df0b2fe2504041ffb4de49b01f04905f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00018-of-00038.safetensors:   0%|          | 0.00/3.81G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c1f7e43e0f44f44a3abcbd823fb2716",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00019-of-00038.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09a04bf25e8b41e190765fd90c0b1344",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00020-of-00038.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "803cc6a5817644b0bce5d11aa06fc5b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00021-of-00038.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67efda88a3894f2aacd7c49354aa7e39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00022-of-00038.safetensors:   0%|          | 0.00/3.81G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b5c77c4dc30497f8d18dd434bf93048",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00023-of-00038.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "582908bad9c4474baa5f0289d1fa33b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00024-of-00038.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdb7e0868b7d404e965b910357879d7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00025-of-00038.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f46e3c478b041409991b9222dd2723d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00026-of-00038.safetensors:   0%|          | 0.00/3.81G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8beda481d1354f479e0cfe30cdda3d32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00027-of-00038.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b309f11a8b624277bf7cd7e38932f668",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00028-of-00038.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "261562ac270e445fa07b6abec8785be2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00029-of-00038.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dac3b5a799bd42eb905b8e6e8e6bfb8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00030-of-00038.safetensors:   0%|          | 0.00/3.81G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b65954f3ed4341dba0e63f223d58372f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00031-of-00038.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6e7e925aa63410aa4d83c8b1f22dcef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00032-of-00038.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6565dededcc42369dd30056d4ef434d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00033-of-00038.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cbf94a9b349412ca22374aee1cfd43c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00034-of-00038.safetensors:   0%|          | 0.00/3.81G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff79894c34234ab0bf538c74b2bc4c64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00035-of-00038.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "169c79ef037e4c1895c0790b925a2834",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00036-of-00038.safetensors:   0%|          | 0.00/4.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef5084f797634fb48f85d16d607831d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00037-of-00038.safetensors:   0%|          | 0.00/2.24G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfe9e1c2c3b54818ac04aa5fba6b6e74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00038-of-00038.safetensors:   0%|          | 0.00/2.49G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Qwen2VLRotaryEmbedding` can now be fully parameterized by passing the model config through the `config` argument. All other arguments will be removed in v4.46\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ee49ffa87c14327b287cdcb888f63a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0fba6e7686a43a8852acabb8cc8dbf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/242 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cdfb2e9605c4ec28028ef422ba044cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/347 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10c239c5246c489eaa564aab27c9fcdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/4.19k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dffd440a54f4b91a3e8caa9760e12aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9ca8194fe7f4a6ab9c1bc9c36930dc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc0a45b23ce741ee8b3b502253ac7863",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcd8f6765a734afea310ed9e8c6ebe0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chat_template.json:   0%|          | 0.00/1.05k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from peft import PeftModel\n",
    "from transformers import AutoProcessor, AutoModelForVision2Seq\n",
    "model_id = \"Qwen/Qwen2-VL-72B-Instruct\" \n",
    "adapter_path = \"./qwen2-7b-instruct-homeworks\"  # 학습된 어댑터 경로\n",
    "base_model_id = \"Qwen/Qwen2-VL-72B-Instruct\"  # 기본 모델 ID\n",
    "merged_path = \"merged\"  # 병합된 모델을 저장할 경로\n",
    "\n",
    "# 기본 모델 로드\n",
    "model = AutoModelForVision2Seq.from_pretrained(model_id, low_cpu_mem_usage=True)\n",
    "\n",
    "# 병합된 모델 저장 경로\n",
    "# LoRA와 기본 모델을 병합하고 저장\n",
    "peft_model = PeftModel.from_pretrained(model, adapter_path)  # PEFT 모델 로드\n",
    "merged_model = peft_model.merge_and_unload()  # 모델 병합\n",
    "merged_model.save_pretrained(merged_path,safe_serialization=True, max_shard_size=\"2GB\")  # 병합된 모델 저장\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(base_model_id)  # 프로세서 로드\n",
    "processor.save_pretrained(merged_path)  # 프로세서 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70229777-f38d-44ab-864f-1405982159f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모두 완료했습니다\n"
     ]
    }
   ],
   "source": [
    "print(\"모두 완료했습니다\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bdc68c0-5d4f-47b7-bcd0-64bacf050327",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unrecognized keys in `rope_scaling` for 'rope_type'='default': {'mrope_section'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d9943fcac4e4d3f838adfac8d28674d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/164 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "local_model_path = \"/workspace/trl/merged\"\n",
    "model = AutoModelForVision2Seq.from_pretrained(local_model_path)\n",
    "processor = AutoProcessor.from_pretrained(local_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5661c48a-9b1b-4ef6-ac64-158a5f91525f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: fineGrained).\n",
      "The token `huggingface` has been saved to /root/.cache/huggingface/stored_tokens\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful.\n",
      "The current active token is: `huggingface`\n"
     ]
    }
   ],
   "source": [
    "!huggingface-cli login --token Your_Huggingface_Token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebb8fd9-6310-456e-a928-65992e4466a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hub_model_id = \"daje/Qwen2-VL-72B-instruct-ScienceQA\"\n",
    "# 허깅페이스 업로드 \n",
    "model.push_to_hub(hub_model_id)\n",
    "processor.push_to_hub(hub_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3c1ce5-f0a2-4197-88c2-c7a7e9c576dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
